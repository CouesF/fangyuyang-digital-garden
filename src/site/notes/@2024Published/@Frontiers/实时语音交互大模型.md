---
{"dg-publish":true,"permalink":"/2024-published/frontiers//","tags":["Frontiers"],"created":"2024-10-10T20:44:03.034+08:00"}
---

关注指标
- 语言模型参数量
- 首次响应延迟
- 是否支持复杂互动：如打断、主动对话、Non-awakening Interaction
- 是否支持多模态输入
- 所需算力

## VITA(开源)

> - 论文： https://arxiv.org/pdf/2408.05211
> - 主页： https://vita-home.github.io/
> - 代码： https://github.com/VITA-MLLM/VITA

![Pasted image 20241010205723.png|500](/img/user/Attachment/Pasted%20image%2020241010205723.png)
- 语言模型参数量
    - Mixtral 8×7 B: 7 billion parameters
- 首次响应延迟
    - **首次响应延迟**一般在**1-2秒**以内。
- 是否支持复杂互动：
    - 支持打断和主动对话
    - 支持 Non-awakening Interaction
- 是否支持多模态输入
    - 支持多模态：视频、图片、文本、音频
- 所需算力
    - 需要高性能计算设备。“**Use high-performance GPUs for deployment**. In the demo video, we use 4 Nvidia H20 GPUs. A800, H800, or A100 will be much better.”

## MoshiChat(开源)

> 代码： https://github.com/kyutai-labs/moshi  
> 模型： https://huggingface.co/collections/kyutai/moshi-v01-release-66eaeaf3302bef6bd9ad7acd
> 报告：  https://kyutai.org/Moshi.pdf  
> 发布时间：2024.07.04

- 语言模型参数量
    - Moshi 使用了 7 B 参数的 Temporal Transformer
- 首次响应延迟
    - Moshi 理论延迟为 160 ms，实践中在 `L4 GPU` 上可低至 200ms
- 是否支持复杂互动
    - Moshi 支持双向流音频对话，并通过预测自身的“内在独白”来提升生成质量
    - 未明确提及打断或 Non-awakening Interaction（非唤醒交互）
    - 模型的双流交互设计可能有助于支持主动对话
- 是否支持多模态输入
    - 主要处理语音和文本，未提及多模态输入支持
- 所需算力
    - PyTorch 版本需要 24 GB 以上的 GPU 内存
    - Rust 版本后端需安装 CUDA，macOS 支持 Metal 加速


## LLaMA-Omni(开源)

> - 论文： https://arxiv.org/pdf/2409.06666
> - 代码： https://github.com/ictnlp/LLaMA-Omni
> - 模型： https://huggingface.co/ICTNLP/Llama-3.1-8B-Omni

![Pasted image 20241010204745.png|500](/img/user/Attachment/Pasted%20image%2020241010204745.png)

- 语言模型参数量
	- Llama-3.1-8 B-Instruct
- 首次响应延迟
	- 226 ms
- 是否支持复杂互动
	- 包含打断、主动对话
	- Non-awakening Interaction
- 是否支持多模态输入
	- 支持
- 所需算力
	- 训练使用 4 个 GPU，时长小于 3天
- Speech Encoder：`Whisper-large-v3`


